{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiSnm4IU5MVe",
        "outputId": "3d482e65-e366-4a20-ad22-9131deeaa84c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - loss: 0.3050 - val_loss: 0.8252\n",
            "Epoch 2/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.2223 - val_loss: 0.5733\n",
            "Epoch 3/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.1274 - val_loss: 0.3706\n",
            "Epoch 4/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0719 - val_loss: 0.2126\n",
            "Epoch 5/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0376 - val_loss: 0.1000\n",
            "Epoch 6/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0214 - val_loss: 0.0358\n",
            "Epoch 7/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0204 - val_loss: 0.0154\n",
            "Epoch 8/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0245 - val_loss: 0.0156\n",
            "Epoch 9/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0173 - val_loss: 0.0235\n",
            "Epoch 10/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0181 - val_loss: 0.0366\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
            "Predicted: 118.5783 | Actual: 124.2626\n",
            "Predicted: 118.9923 | Actual: 140.6077\n",
            "Predicted: 117.7552 | Actual: 134.2758\n",
            "Predicted: 118.8632 | Actual: 142.0477\n",
            "Predicted: 119.2762 | Actual: 128.8965\n",
            "Predicted: 120.8451 | Actual: 134.8819\n",
            "Predicted: 120.3169 | Actual: 138.9151\n",
            "Predicted: 120.0861 | Actual: 140.1339\n",
            "Predicted: 120.5035 | Actual: 138.6588\n",
            "Predicted: 121.2418 | Actual: 145.0334\n"
          ]
        }
      ],
      "source": [
        "# Minimal GRU for univariate next-step prediction (Colab-ready)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense\n",
        "\n",
        "# --- load data (assumes common_dataset.csv with column 'value') ---\n",
        "df = pd.read_csv('dataset.csv')\n",
        "series = df['value'].astype('float32').values.reshape(-1, 1)\n",
        "\n",
        "# --- scale to [0,1] ---\n",
        "scaler = MinMaxScaler()\n",
        "series_s = scaler.fit_transform(series)\n",
        "\n",
        "# --- create sequences (seq_len timesteps -> next value) ---\n",
        "seq_len = 10\n",
        "X, y = [], []\n",
        "for i in range(len(series_s) - seq_len):\n",
        "    X.append(series_s[i:i + seq_len])\n",
        "    y.append(series_s[i + seq_len])\n",
        "X = np.array(X)   # shape: (samples, seq_len, 1)\n",
        "y = np.array(y)   # shape: (samples, 1)\n",
        "\n",
        "# --- train/test split (80/20) ---\n",
        "train_size = int(0.8 * len(X))\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "# --- build GRU model ---\n",
        "model = Sequential([\n",
        "    GRU(32, input_shape=(seq_len, 1)),  # 32 GRU units\n",
        "    Dense(1)                            # predict single next value\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# --- train (minimal epochs) ---\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "# --- predict and invert scaling ---\n",
        "pred_s = model.predict(X_test)\n",
        "pred = scaler.inverse_transform(pred_s)\n",
        "y_true = scaler.inverse_transform(y_test)\n",
        "\n",
        "# --- show sample predictions ---\n",
        "for i in range(min(10, len(pred))):\n",
        "    print(f\"Predicted: {pred[i,0]:.4f} | Actual: {y_true[i,0]:.4f}\")\n"
      ]
    }
  ]
}