{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# LSTM for Time Series Prediction\n",
        "# -------------------------------\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# -------------------------------\n",
        "# 1️⃣ Load the dataset\n",
        "# -------------------------------\n",
        "# Assume 'dataset.csv' is uploaded and contains a single numeric column named 'value'\n",
        "df = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Convert the column to float values and reshape for scaling\n",
        "series = df['value'].astype('float32').values.reshape(-1, 1)\n",
        "\n",
        "# -------------------------------\n",
        "# 2️⃣ Normalize the data\n",
        "# -------------------------------\n",
        "# LSTMs perform better when input values are in the range [0, 1]\n",
        "scaler = MinMaxScaler()\n",
        "series_s = scaler.fit_transform(series)\n",
        "\n",
        "# -------------------------------\n",
        "# 3️⃣ Create input-output sequences\n",
        "# -------------------------------\n",
        "# Each input sequence (X) will have 'seq_len' time steps predicting the next value (y)\n",
        "seq_len = 10  # You can change the number of time steps\n",
        "X, y = [], []\n",
        "for i in range(len(series_s) - seq_len):\n",
        "    X.append(series_s[i:i + seq_len])\n",
        "    y.append(series_s[i + seq_len])\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X = np.array(X)   # Shape: (samples, seq_len, 1)\n",
        "y = np.array(y)   # Shape: (samples, 1)\n",
        "\n",
        "# -------------------------------\n",
        "# 4️⃣ Split into training and testing sets\n",
        "# -------------------------------\n",
        "train_size = int(0.8 * len(X))  # 80% for training\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "# -------------------------------\n",
        "# 5️⃣ Build the LSTM model\n",
        "# -------------------------------\n",
        "model = Sequential([\n",
        "    LSTM(32, input_shape=(seq_len, 1)),  # 32 memory units, input shape = (timesteps, features)\n",
        "    Dense(1)                             # Output layer with one neuron (predicting next value)\n",
        "])\n",
        "\n",
        "# Compile with Mean Squared Error loss and Adam optimizer\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# -------------------------------\n",
        "# 6️⃣ Train the model\n",
        "# -------------------------------\n",
        "# epochs = number of passes through training data\n",
        "# batch_size = number of samples per gradient update\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "# -------------------------------\n",
        "# 7️⃣ Make predictions and compare\n",
        "# -------------------------------\n",
        "pred_s = model.predict(X_test)\n",
        "\n",
        "# Inverse transform to original scale\n",
        "pred = scaler.inverse_transform(pred_s)\n",
        "y_true = scaler.inverse_transform(y_test)\n",
        "\n",
        "# -------------------------------\n",
        "# 8️⃣ Display sample results\n",
        "# -------------------------------\n",
        "print(\"Predicted vs Actual values:\\n\")\n",
        "for i in range(min(10, len(pred))):\n",
        "    print(f\"Predicted: {pred[i,0]:.4f} | Actual: {y_true[i,0]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLvngDWq2bXv",
        "outputId": "ef9afb23-ad4b-4189-d606-681bf2c50a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.3754 - val_loss: 0.9337\n",
            "Epoch 2/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2396 - val_loss: 0.6574\n",
            "Epoch 3/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1764 - val_loss: 0.4269\n",
            "Epoch 4/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0907 - val_loss: 0.2417\n",
            "Epoch 5/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0529 - val_loss: 0.1010\n",
            "Epoch 6/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0201 - val_loss: 0.0215\n",
            "Epoch 7/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0095 - val_loss: 0.0025\n",
            "Epoch 8/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0130 - val_loss: 0.0032\n",
            "Epoch 9/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0139 - val_loss: 0.0027\n",
            "Epoch 10/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0090 - val_loss: 0.0085\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
            "Predicted vs Actual values:\n",
            "\n",
            "Predicted: 127.3720 | Actual: 124.2626\n",
            "Predicted: 128.2852 | Actual: 140.6077\n",
            "Predicted: 127.7287 | Actual: 134.2758\n",
            "Predicted: 128.4914 | Actual: 142.0477\n",
            "Predicted: 129.3285 | Actual: 128.8965\n",
            "Predicted: 131.0157 | Actual: 134.8819\n",
            "Predicted: 131.2922 | Actual: 138.9151\n",
            "Predicted: 131.9738 | Actual: 140.1339\n",
            "Predicted: 131.9245 | Actual: 138.6588\n",
            "Predicted: 132.3329 | Actual: 145.0334\n"
          ]
        }
      ]
    }
  ]
}